{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IykxaBAmrolD"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import zipfile\n",
        "import cv2\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.decomposition import PCA\n",
        "from google.colab import files\n",
        "import matplotlib.pyplot as plt\n",
        "import gdown\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "\n",
        "class DatasetPreparation:\n",
        "    def __init__(self, dataset_zip_path):\n",
        "        self.dataset_zip_path = dataset_zip_path\n",
        "        self.images = []\n",
        "        self.labels = []\n",
        "        self.extract_dataset()\n",
        "\n",
        "    def extract_dataset(self):\n",
        "        with zipfile.ZipFile(self.dataset_zip_path, 'r') as zip_ref:\n",
        "            zip_ref.extractall('dataset')\n",
        "\n",
        "        for filename in os.listdir('dataset/DataSet_04'):\n",
        "            file_path = os.path.join('dataset/DataSet_04', filename)\n",
        "            label = int(filename.split('_')[0])\n",
        "            image = cv2.imread(file_path, 0)  # Read as grayscale\n",
        "            image = cv2.resize(image, (128, 128))  # Resize the image to 128x128 pixels\n",
        "            self.images.append(image)\n",
        "            self.labels.append(label)\n",
        "\n",
        "class FeatureExtraction:\n",
        "    def hog_features(self, images):\n",
        "        return np.array([self.hog_descriptor(image) for image in images])\n",
        "\n",
        "    def hog_descriptor(self, image):\n",
        "        winSize = (128, 128)\n",
        "        blockSize = (16, 16)\n",
        "        blockStride = (8, 8)\n",
        "        cellSize = (8, 8)\n",
        "        nbins = 9\n",
        "        derivAperture = 1\n",
        "        winSigma = -1\n",
        "        histogramNormType = 0\n",
        "        L2HysThreshold = 0.2\n",
        "        gammaCorrection = 1\n",
        "        nlevels = 128\n",
        "        hog = cv2.HOGDescriptor(winSize, blockSize, blockStride, cellSize, nbins, derivAperture, winSigma,\n",
        "                                histogramNormType, L2HysThreshold, gammaCorrection, nlevels)\n",
        "        return hog.compute(image).flatten()\n",
        "\n",
        "    def pca_features(self, images, n_components=100):\n",
        "        flat_images = images.reshape(images.shape[0], -1)\n",
        "        pca = PCA(n_components=n_components)\n",
        "        return pca.fit_transform(flat_images)\n",
        "\n",
        "    def flatten_images(self, images):\n",
        "        return images.reshape(images.shape[0], -1)\n",
        "\n",
        "class PatternRecognition:\n",
        "    def __init__(self):\n",
        "        self.classifiers = {\n",
        "            'KNN': KNeighborsClassifier(n_neighbors=3),\n",
        "            'SVM': SVC(kernel='linear')\n",
        "        }\n",
        "\n",
        "    def train_classifier(self, classifier, X_train, y_train):\n",
        "        self.classifiers[classifier].fit(X_train, y_train)\n",
        "\n",
        "    def predict_classifier(self, classifier, X_test):\n",
        "        return self.classifiers[classifier].predict(X_test)\n",
        "\n",
        "    def accuracy(self, y_true, y_pred):\n",
        "        return accuracy_score(y_true, y_pred)\n",
        "\n",
        "def download_dataset():\n",
        "    url = \"https://drive.google.com/uc?export=download&id=1QvluzGHbalr_-PQ4oeh8QtvbaGhMMwmr\"\n",
        "    dataset_zip_path = \"DataSet_04.zip\"\n",
        "    gdown.download(url, dataset_zip_path, quiet=False)\n",
        "    print(\"Download complete.\")\n",
        "\n",
        "def run_experiments(dataset_zip_path):\n",
        "    dataset = DatasetPreparation(dataset_zip_path)\n",
        "    images = np.array(dataset.images)\n",
        "    labels = np.array(dataset.labels)\n",
        "\n",
        "    feature_extractor = FeatureExtraction()\n",
        "    pattern_recognizer = PatternRecognition()\n",
        "\n",
        "    train_test_ratios = [0.6, 0.7, 0.8]\n",
        "    results = []\n",
        "\n",
        "    for ratio in tqdm(train_test_ratios, desc=\"Train-Test Ratios\"):\n",
        "        X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=1-ratio, random_state=42)\n",
        "\n",
        "        for feat_extraction in ['None', 'HOG']:\n",
        "            X_train_feat, X_test_feat = None, None\n",
        "            if feat_extraction == 'HOG':\n",
        "                X_train_feat, X_test_feat = feature_extractor.hog_features(X_train), feature_extractor.hog_features(X_test)\n",
        "            elif feat_extraction == 'PCA':\n",
        "                X_train_feat, X_test_feat = feature_extractor.pca_features(X_train), feature_extractor.pca_features(X_test)\n",
        "            elif feat_extraction == 'None':\n",
        "                X_train_feat, X_test_feat = feature_extractor.flatten_images(X_train), feature_extractor.flatten_images(X_test)\n",
        "\n",
        "            for classifier in ['KNN', 'SVM']:\n",
        "                pattern_recognizer.train_classifier(classifier, X_train_feat, y_train)\n",
        "                y_pred = pattern_recognizer.predict_classifier(classifier, X_test_feat)\n",
        "                acc = pattern_recognizer.accuracy(y_test, y_pred)\n",
        "                results.append({\n",
        "                    'Feature Extraction': feat_extraction,\n",
        "                    'Pattern Recognition': classifier,\n",
        "                    f'{int(ratio*100)}': acc\n",
        "                })\n",
        "\n",
        "    # Format results as a table\n",
        "    df_results = pd.DataFrame(results).groupby(['Feature Extraction', 'Pattern Recognition']).mean().reset_index()\n",
        "    print(df_results)\n",
        "    df_results\n",
        "\n",
        "def upload_and_predict():\n",
        "    feature_extractor = FeatureExtraction()\n",
        "    dataset = DatasetPreparation(\"DataSet_04.zip\")\n",
        "    images = np.array(dataset.images)\n",
        "    labels = np.array(dataset.labels)\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.3, random_state=42)\n",
        "    X_train_features = feature_extractor.hog_features(X_train)\n",
        "\n",
        "    uploaded = files.upload()\n",
        "    for file_name in uploaded.keys():\n",
        "        image = cv2.imread(file_name, 0)  # Read as grayscale\n",
        "        image = cv2.resize(image, (128, 128))  # Resize to 128x128 pixels\n",
        "        image_feature = feature_extractor.hog_descriptor(image).reshape(1, -1)\n",
        "\n",
        "        knn = KNeighborsClassifier(n_neighbors=3)\n",
        "        knn.fit(X_train_features, y_train)\n",
        "        prediction = knn.predict(image_feature)\n",
        "\n",
        "        plt.imshow(image, cmap='gray')\n",
        "        plt.title(f'Predicted Label: {prediction[0]}')\n",
        "        plt.show()\n",
        "        print(f'Image predicted: {prediction[0]}')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Download the dataset\")\n",
        "download_dataset()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YHk-s7xJru0J",
        "outputId": "39c75f19-533f-4b63-c1b4-fcbadda49255"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Download the dataset\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?export=download&id=1QvluzGHbalr_-PQ4oeh8QtvbaGhMMwmr\n",
            "To: /content/DataSet_04.zip\n",
            "100%|██████████| 14.7M/14.7M [00:00<00:00, 106MB/s] "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Download complete.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Experiments with different train-test ratios\")\n",
        "run_experiments(\"DataSet_04.zip\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "or2odxqUrzGM",
        "outputId": "c4a846dc-5200-491f-ba9a-c5f97e32e091"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Experiments with different train-test ratios\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train-Test Ratios: 100%|██████████| 3/3 [12:44<00:00, 254.98s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Feature Extraction Pattern Recognition        60        70        80\n",
            "0                HOG                 KNN  0.913519  0.916483  0.922465\n",
            "1                HOG                 SVM  0.974818  0.974812  0.976806\n",
            "2               None                 KNN  0.407886  0.417587  0.423459\n",
            "3               None                 SVM  0.899934  0.897481  0.897946\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Upload an image to predict its label\")\n",
        "upload_and_predict()"
      ],
      "metadata": {
        "id": "O0BycHsar1Dm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}